{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48cce82-ee8f-42d6-8ac4-0a642ca498fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get datasets from task 1\n",
    "%run task3_1.ipynb     #this is were my function was stored\n",
    "initFeatures, starsTarget = getStarsInitial()\n",
    "starsTarget = encodeStars(starsTarget)\n",
    "starsFeatures = pruneStars(imputeStars(initFeatures), starsTarget)\n",
    "\n",
    "initDatasetDate, initDatasetCategorical, initDatasetNumerical, garmentTarget = getGarmentInitial()\n",
    "datasetDate = garmentDetectAndEncodeDate(dateImputeAbove(initDatasetDate))\n",
    "datasetCategorical = garmentEncodeCategorical(imputeAboveMultiple(initDatasetCategorical))\n",
    "garmentDataset = pruneGarment(concatenateAndImputeNumericalGarment(datasetDate,datasetCategorical,initDatasetNumerical), garmentTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b302235-7137-4e69-9220-9cc2e0813d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def starsSVC(starsFeatures,starsTarget):\n",
    "    '''Performs support vector classification on the stars dataset and outputs information about results '''\n",
    "    #import modules\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, explained_variance_score\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import KFold \n",
    "    #standardize the features using minmax\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    starsFeatures = mms.fit_transform(starsFeatures)\n",
    "    \n",
    "    #prepare k fold using 10 splits\n",
    "    kf = KFold(n_splits=10)\n",
    "    #arrays to hold information about variance and accuracy for each fold\n",
    "    variance = np.zeros(10)\n",
    "    scores = np.zeros(10)\n",
    "    i = 0\n",
    "    #for each fold, fit the model and obtain accuracy and variance\n",
    "    for train_idx, test_idx in kf.split(starsFeatures):\n",
    "        features_train_kfold, features_test_kfold = starsFeatures[train_idx], starsFeatures[test_idx]\n",
    "        labels_train_kfold, labels_test_kfold = starsTarget[train_idx], starsTarget[test_idx]\n",
    "        #fit the model and generate predictions\n",
    "        model = LinearSVC().fit(features_train_kfold, labels_train_kfold)\n",
    "        model_pred = np.around(model.predict(features_test_kfold))\n",
    "        scores[i] = accuracy_score(labels_test_kfold, model_pred)\n",
    "        variance[i] = explained_variance_score(labels_test_kfold, model_pred)\n",
    "        print(variance[i])\n",
    "        i = i + 1\n",
    "\n",
    "    print(\"average accuracy\",scores.mean())\n",
    "    print(\"variance:\",variance.mean())\n",
    "    \n",
    "    #create a new model to use to create a graph\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(starsFeatures, starsTarget, test_size=0.25)\n",
    "    \n",
    "    model = LinearSVC().fit(features_train, labels_train)\n",
    "    print('Training:', model.score(features_train, labels_train))\n",
    "    print('Testing:', model.score(features_test, labels_test))\n",
    "    \n",
    "    \n",
    "    # compute predictions for samples in the testing dataset, rounded to nearest integer\n",
    "    model_pred = np.around(model.predict(features_test))\n",
    "    print(\"accuracy:\",accuracy_score(labels_test, model_pred))\n",
    "    #create graph\n",
    "    ConfusionMatrixDisplay.from_predictions(labels_test, model_pred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0633cf5-2c89-4ba9-a2df-65937fe8f58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#starsSVC(starsFeatures,starsTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03ce9b-0357-4fba-b609-34ff05cd6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garmentSVR(garmentDataset, garmentTarget):\n",
    "    '''Performs support vector regression on the garment dataset and outputs information about results'''\n",
    "    #import modules\n",
    "    from sklearn.svm import SVR, SVC, LinearSVR\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import mean_squared_error, ConfusionMatrixDisplay, precision_score, recall_score, accuracy_score, explained_variance_score\n",
    "    from sklearn.model_selection import KFold \n",
    "    #standardize the features\n",
    "    mms = MinMaxScaler(feature_range=(-1, 1))\n",
    "    garmentDataset = mms.fit_transform(garmentDataset)\n",
    "    \n",
    "    #prepare k fold\n",
    "    kf = KFold(n_splits=10)\n",
    "    #arrays for measuring data across folds\n",
    "    scores = np.zeros(10)\n",
    "    variance = np.zeros(10)\n",
    "    i = 0\n",
    "    #for each gold create a model\n",
    "    for train_idx, test_idx in kf.split(garmentDataset):\n",
    "        features_train_kfold, features_test_kfold = garmentDataset[train_idx], garmentDataset[test_idx]\n",
    "        labels_train_kfold, labels_test_kfold = garmentTarget[train_idx], garmentTarget[test_idx]\n",
    "        #fit the model and generate predictions\n",
    "        model = SVR(max_iter=1000000)\n",
    "        model.fit(features_train_kfold, labels_train_kfold)\n",
    "        model_pred = model.predict(features_test_kfold)\n",
    "        scores[i] = mean_squared_error(labels_test_kfold, model_pred, squared=False)\n",
    "        variance[i] = explained_variance_score(labels_test_kfold, model_pred)\n",
    "        print(\"variance\",variance[i])\n",
    "        i = i + 1\n",
    "\n",
    "    print(\"average error\",scores.mean())\n",
    "    print(\"variance:\",variance.mean())\n",
    "\n",
    "    #create graph of a model output\n",
    "    features_train, features_test, labels_train, labels_test = train_test_split(garmentDataset, garmentTarget, test_size=0.25)\n",
    "    \n",
    "    model = SVR(max_iter=1000000)\n",
    "    model.fit(features_train, labels_train)\n",
    "    \n",
    "    # compute predictions for samples in the testing dataset\n",
    "    model_pred = model.predict(features_test)\n",
    "\n",
    "    # scatter plot of actual and predicted values for the target variable for first 10 samples\n",
    "    plt.plot(labels_test[:10], 'o', label='Actual')\n",
    "    plt.plot(model_pred[:10], 'o', label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Index of sample') # label of x-axis\n",
    "    plt.ylabel('Actual/Predicted value of the target') # label of y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdaa81-2e4c-4651-800f-c7ea07073c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "garmentSVR(garmentDataset, garmentTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cd4f2-9309-4d0f-85a1-e60eadd564fb",
   "metadata": {},
   "source": [
    "Markdown question for task3_3:\n",
    "For the garment dataset, I am using a hypothesis that support vector regression will give a lower mean squared error than linear regression. Sample size is 10 and mean difference is 0.05222890958. Linear regression variance, removing below 0 results, is 0.1504525. Support vector regression edited variance is 0.12235682528. This gives a t value of 0.316. Therefore the percentage for the original hypothesis is from 0 to 50%, and therefore we should reject the original hypothesis due to lack of trust.\n",
    "\n",
    "For the stars dataset, my hypothesis is that accuracy will be higher for support vector classification than linear regression. Sample size is 10, mean difference for accuracy is 0.3618799. Linear regression variance is 0.08103333333. SVC variance is 0.5820865909366972. This gives a T value of 1.483, corresponding to 80% chance. Therefore I reject the null hypothesis that linear regression is better than SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4daeed4-e774-474b-be0f-7cea0c3c5465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e787c655-d94c-44ba-ab83-f45315f0f75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
