{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6a2bb1-fa6e-4e88-9f23-befd7b4a0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get datasets from task 1\n",
    "%run task3_1.ipynb     #this is were my function was stored\n",
    "initFeatures, starsTarget = getStarsInitial()\n",
    "starsTarget = encodeStars(starsTarget)\n",
    "starsFeatures = pruneStars(imputeStars(initFeatures), starsTarget)\n",
    "\n",
    "initDatasetDate, initDatasetCategorical, initDatasetNumerical, garmentTarget = getGarmentInitial()\n",
    "datasetDate = garmentDetectAndEncodeDate(dateImputeAbove(initDatasetDate))\n",
    "datasetCategorical = garmentEncodeCategorical(imputeAboveMultiple(initDatasetCategorical))\n",
    "garmentDataset = pruneGarment(concatenateAndImputeNumericalGarment(datasetDate,datasetCategorical,initDatasetNumerical), garmentTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f38e5c-d9f7-4d03-a8bb-bea1a84dfbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MBKMeansStars(starsFeatures,starsTarget):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    '''Performs eager clustering on the stars dataset and outputs information about results '''\n",
    "    #import modules\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, explained_variance_score\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "    from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "    \n",
    "    #prepare k fold using 10 splits\n",
    "    kf = KFold(n_splits=10)\n",
    "    #arrays to hold information about variance and accuracy for each fold\n",
    "    scores = np.zeros(10)\n",
    "    iterator = 0\n",
    "    #for each fold, fit the model and obtain accuracy and variance\n",
    "    for train_idx, test_idx in kf.split(starsFeatures):\n",
    "        features_train_kfold, features_test_kfold = starsFeatures[train_idx], starsFeatures[test_idx]\n",
    "        labels_train_kfold, labels_test_kfold = starsTarget[train_idx], starsTarget[test_idx]\n",
    "        \n",
    "        #prepare clustering with 3 clusters\n",
    "        mbkm = MiniBatchKMeans(n_clusters=3, batch_size=2048)\n",
    "        mbkm.fit(features_train_kfold)\n",
    "        \n",
    "        cluster_assoc = -1 * np.ones(3)\n",
    "\n",
    "        for i, cls in enumerate([0, 1, 2]):\n",
    "            cluster_sample_cls = labels_train_kfold[mbkm.labels_ == cls] # class of each sample in the cluster\n",
    "            cls_in_cluster, cls_count = np.unique(cluster_sample_cls, return_counts=True) # identify the number of samples from each class in the cluster\n",
    "            cluster_assoc[i] = cls_in_cluster[np.argmax(cls_count)] # assign the most prominent class in the cluster as the class association of the cluster\n",
    "        \n",
    "        #accuracy for fold\n",
    "        scores[iterator] = (np.sum(mbkm.predict(features_test_kfold) == labels_test_kfold) / labels_test_kfold.size)\n",
    "        print(scores[iterator])\n",
    "        iterator = iterator + 1\n",
    "\n",
    "    print(scores)\n",
    "    print(\"average accuracy\",scores.mean())\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6083a31-fbd8-4719-8ed1-bedaeae41764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3355\n",
      "0.3468\n",
      "0.3413\n",
      "0.236\n",
      "0.3663\n",
      "0.3353\n",
      "0.1898\n",
      "0.3365\n",
      "0.3225\n",
      "0.204\n",
      "[0.3355 0.3468 0.3413 0.236  0.3663 0.3353 0.1898 0.3365 0.3225 0.204 ]\n",
      "average accuracy 0.3014\n"
     ]
    }
   ],
   "source": [
    "MBKMeansStars(starsFeatures,starsTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4adf3-7716-4cf4-bbe3-223668b8becf",
   "metadata": {},
   "source": [
    "Markdown question for task3_4:\n",
    "One way to compare the effectiveness of two machine learning algorithms is by comparing their accuracy. In ordert to ensure that a reliable estimate of accuracy is obtained, the mean accuracy will be taken from 10 k folds. Using 10 k folds means that the accuracy we will use to compare the algorithms is a good representation of the learning algorithm, rather than just a lucky occurence due to training and test data selection.\n",
    "\n",
    "The average accuracy of the mini batch k means clustering algorithm for the pruned stars dataset was found to be 30.14%, while the average accuracy for the support vector classification algorithm was found to be 89.15%. Therefore, it is suitable to say that the support vector classification algorithm performs better than the mini batch k means clustering algorithm for the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
